{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft</th>\n",
       "      <th>floors</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>221900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>538000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>604000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>510000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1230000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>257500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>291850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>229500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6560</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>323000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>662500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>468000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19901</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>310000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4850</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>530000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>650000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>395000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4300</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>485000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>189000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>230000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>385000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>285000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>252700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>329000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4697</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>233000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2691</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>937000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1581</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>667000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>438000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7173</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>719000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>1157</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>399950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>900</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>380000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21586</th>\n",
       "      <td>1201</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>505000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21587</th>\n",
       "      <td>1488</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>385000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21588</th>\n",
       "      <td>1278</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>414500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21589</th>\n",
       "      <td>4760</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>347500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21590</th>\n",
       "      <td>9444</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1220000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21591</th>\n",
       "      <td>3852</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>572000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>1200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>475000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>8142</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1090000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>5995</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>350000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>981</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>520000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>9437</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>679950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>10125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1580000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21598</th>\n",
       "      <td>7866</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>541800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21599</th>\n",
       "      <td>7838</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>810000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21600</th>\n",
       "      <td>8088</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21601</th>\n",
       "      <td>1179</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>467000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21602</th>\n",
       "      <td>11968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>224000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21603</th>\n",
       "      <td>5536</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>507250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21604</th>\n",
       "      <td>1126</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>429000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21605</th>\n",
       "      <td>6023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>610685.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21606</th>\n",
       "      <td>7200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1010000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21607</th>\n",
       "      <td>1294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>475000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>360000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>402101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>325000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sqft  floors  bedrooms  bathrooms      price\n",
       "0        5650     1.0         3       1.00   221900.0\n",
       "1        7242     2.0         3       2.25   538000.0\n",
       "2       10000     1.0         2       1.00   180000.0\n",
       "3        5000     1.0         4       3.00   604000.0\n",
       "4        8080     1.0         3       2.00   510000.0\n",
       "5      101930     1.0         4       4.50  1230000.0\n",
       "6        6819     2.0         3       2.25   257500.0\n",
       "7        9711     1.0         3       1.50   291850.0\n",
       "8        7470     1.0         3       1.00   229500.0\n",
       "9        6560     2.0         3       2.50   323000.0\n",
       "10       9796     1.0         3       2.50   662500.0\n",
       "11       6000     1.0         2       1.00   468000.0\n",
       "12      19901     1.5         3       1.00   310000.0\n",
       "13       9680     1.0         3       1.75   400000.0\n",
       "14       4850     1.5         5       2.00   530000.0\n",
       "15       5000     2.0         4       3.00   650000.0\n",
       "16      14040     2.0         3       2.00   395000.0\n",
       "17       4300     1.5         4       1.00   485000.0\n",
       "18       9850     1.0         2       1.00   189000.0\n",
       "19       9774     1.0         3       1.00   230000.0\n",
       "20       4980     1.0         4       1.75   385000.0\n",
       "21      44867     1.0         3       2.75  2000000.0\n",
       "22       6300     2.0         5       2.50   285000.0\n",
       "23       9643     1.0         2       1.50   252700.0\n",
       "24       6500     2.0         3       2.25   329000.0\n",
       "25       4697     1.5         3       2.00   233000.0\n",
       "26       2691     2.0         3       1.75   937000.0\n",
       "27       1581     1.5         3       1.00   667000.0\n",
       "28       6380     1.0         3       1.75   438000.0\n",
       "29       7173     2.0         4       2.50   719000.0\n",
       "...       ...     ...       ...        ...        ...\n",
       "21583    1157     2.0         2       1.00   399950.0\n",
       "21584     900     2.0         3       2.50   380000.0\n",
       "21585    5000     2.0         3       2.50   270000.0\n",
       "21586    1201     3.0         2       2.50   505000.0\n",
       "21587    1488     3.0         3       2.50   385000.0\n",
       "21588    1278     2.0         2       1.50   414500.0\n",
       "21589    4760     2.0         3       2.50   347500.0\n",
       "21590    9444     1.5         4       3.50  1220000.0\n",
       "21591    3852     2.0         4       2.75   572000.0\n",
       "21592    1200     3.0         3       2.25   475000.0\n",
       "21593    8142     2.0         5       3.75  1090000.0\n",
       "21594    5995     2.0         4       2.75   350000.0\n",
       "21595     981     3.0         2       2.25   520000.0\n",
       "21596    9437     2.0         5       2.75   679950.0\n",
       "21597   10125     2.0         4       3.25  1580000.0\n",
       "21598    7866     2.0         4       2.50   541800.0\n",
       "21599    7838     2.0         4       3.00   810000.0\n",
       "21600    8088     2.0         5       3.75  1540000.0\n",
       "21601    1179     3.0         3       2.50   467000.0\n",
       "21602   11968     1.0         3       1.75   224000.0\n",
       "21603    5536     2.0         3       2.50   507250.0\n",
       "21604    1126     3.0         3       2.00   429000.0\n",
       "21605    6023     2.0         4       2.50   610685.0\n",
       "21606    7200     2.0         4       3.50  1010000.0\n",
       "21607    1294     2.0         3       2.50   475000.0\n",
       "21608    1131     3.0         3       2.50   360000.0\n",
       "21609    5813     2.0         4       2.50   400000.0\n",
       "21610    1350     2.0         2       0.75   402101.0\n",
       "21611    2388     2.0         3       2.50   400000.0\n",
       "21612    1076     2.0         2       0.75   325000.0\n",
       "\n",
       "[21613 rows x 5 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing modules and reading the data set\n",
    "import pandas as pd, numpy as np, csv \n",
    "import matplotlib.pyplot as plt\n",
    "ds = pd.read_csv('kc_house_data.csv')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data set\n",
    "ds = (ds - ds.mean())/ds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing data set into training and testing data sets\n",
    "training_ds = ds[0:int(0.8*len(ds))].as_matrix()\n",
    "training_ds = np.insert(training_ds,0,1,axis=1)\n",
    "test_ds = ds[int(0.8*len(ds)):len(ds)].as_matrix()\n",
    "test_ds = np.insert(test_ds,0,1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diving into features and output\n",
    "train_x = training_ds[:,:-1]\n",
    "train_y = training_ds[:,-1]\n",
    "test_x = test_ds[:,:-1]\n",
    "test_y = test_ds[:,-1]\n",
    "alpha = 0.05 # Learning rate\n",
    "n = train_x.shape[1] # No. of features\n",
    "theta = np.random.randn(n) # Initial value of thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function is mean squared error\n",
    "def cost_function(x,y,theta):\n",
    "    m = len(x)\n",
    "    error = np.sum((x.dot(theta)-y).dot(x.dot(theta)-y))\n",
    "    error= error/(2*m)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error function\n",
    "def rmse(x,y,theta):\n",
    "    m = len(x)\n",
    "    error = np.sum((x.dot(theta)-y).dot(x.dot(theta)-y))\n",
    "    error = math.sqrt(error/m)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for gradient descent without regularization\n",
    "def gradient_descent_wo_regularization(x,y,theta,alpha):\n",
    "    m = len(x)\n",
    "    itera = 0\n",
    "    loss = []\n",
    "    while itera != 1000 :\n",
    "#         print(\"Iteration : \",itera)\n",
    "        prev_cost = rmse(x,y,theta)\n",
    "        loss.append(prev_cost)\n",
    "        theta = theta - ((alpha)*np.sum(((x.dot(theta)-y))*x.T,axis=1))/m\n",
    "        itera = itera+1\n",
    "#     plt.plot(range(0,len(loss)),loss, label = 'Gradient_Descent')\n",
    "#         print(\"Cost : \",cost_function(x,y,theta))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def irls_predict(x, theta):\n",
    "    return x.dot(theta)\n",
    "\n",
    "def irls(x,y,theta):\n",
    "    loss = []\n",
    "    itera = 0\n",
    "    while itera!=1000:\n",
    "        prev_cost = rmse(x,y,theta)\n",
    "        loss.append(prev_cost)\n",
    "        itera = itera + 1\n",
    "        theta = theta - np.linalg.inv(x.T.dot(x)).dot(x.T.dot(x).dot(theta) - x.T.dot(y))\n",
    "#         print (\"Iteration: \", itera, \" RMSE: \", prev_cost)\n",
    "#     plt.plot(range(0,len(loss)),loss, label = 'IRLS')\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate GD:  0.0  , Thetas :  [ 1.  1.  1.  1.  1.]\n",
      "Learning Rate IRLS:  0.0  , Thetas :  [ 0.0008177   0.08097741  0.00915992  0.07491422  0.24162522]\n",
      "Learning Rate GD:  0.0111111111111  , Thetas :  [ 0.01797919  0.99027491  0.75013572  0.97289086  0.85434827]\n",
      "Learning Rate IRLS:  0.0111111111111  , Thetas :  [ 0.0008177   0.08097741  0.00915992  0.07491422  0.24162522]\n",
      "Learning Rate GD:  0.0222222222222  , Thetas :  [ 0.01355606  0.98155933  0.54840738  0.95016849  0.73413147]\n",
      "Learning Rate IRLS:  0.0222222222222  , Thetas :  [ 0.0008177   0.08097741  0.00915992  0.07491422  0.24162522]\n",
      "Learning Rate GD:  0.0333333333333  , Thetas :  [ 0.01020334  0.97337028  0.39656252  0.93096343  0.63855517]\n",
      "Learning Rate IRLS:  0.0333333333333  , Thetas :  [ 0.0008177   0.08097741  0.00915992  0.07491422  0.24162522]\n",
      "Learning Rate GD:  0.0444444444444  , Thetas :  [ 0.00765588  0.96560207  0.282626    0.91449815  0.56203391]\n",
      "Learning Rate IRLS:  0.0444444444444  , Thetas :  [ 0.0008177   0.08097741  0.00915992  0.07491422  0.24162522]\n",
      "Learning Rate GD:  0.0555555555556  , Thetas :  [ 0.00572191  0.95817342  0.19747303  0.90017634  0.50029064]\n",
      "Learning Rate IRLS:  0.0555555555556  , Thetas :  [ 0.0008177   0.08097741  0.00915992  0.07491422  0.24162522]\n",
      "Learning Rate GD:  0.0666666666667  , Thetas :  [ 0.00425523  0.95102166  0.13415281  0.88754011  0.45004758]\n",
      "Learning Rate IRLS:  0.0666666666667  , Thetas :  [ 0.0008177   0.08097741  0.00915992  0.07491422  0.24162522]\n",
      "Learning Rate GD:  0.0777777777778  , Thetas :  [ 0.00314436  0.94409839  0.08737226  0.8762374   0.40879017]\n",
      "Learning Rate IRLS:  0.0777777777778  , Thetas :  [ 0.0008177   0.08097741  0.00915992  0.07491422  0.24162522]\n",
      "Learning Rate GD:  0.0888888888889  , Thetas :  [ 0.00230436  0.93736612  0.05310222  0.865997    0.37458697]\n",
      "Learning Rate IRLS:  0.0888888888889  , Thetas :  [ 0.0008177   0.08097741  0.00915992  0.07491422  0.24162522]\n",
      "Learning Rate GD:  0.1  , Thetas :  [ 0.00167046  0.93079572  0.02827702  0.85660957  0.34595212]\n",
      "Learning Rate IRLS:  0.1  , Thetas :  [ 0.0008177   0.08097741  0.00915992  0.07491422  0.24162522]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f04a54c9e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    alp = np.linspace(0,0.1,num=10)\n",
    "    rmse_irls = []\n",
    "    rmse_gd = []\n",
    "    for alpha_ in alp:\n",
    "        theta = np.ones(n)\n",
    "        theta = gradient_descent_wo_regularization(train_x,train_y,theta,alpha_)\n",
    "        rmse_gd.append(rmse(test_x,test_y,theta))\n",
    "        print(\"Learning Rate GD: \",alpha_,\" , Thetas : \",theta)\n",
    "        theta = np.ones(n)\n",
    "        theta = irls(train_x,train_y,theta)\n",
    "        rmse_irls.append(rmse(test_x,test_y,theta))\n",
    "        print(\"Learning Rate IRLS: \",alpha_,\" , Thetas : \",theta)\n",
    "#     print(\"RMSE Gradient Descent: \",rmse(test_x,test_y,theta))\n",
    "    plt.plot(alp,rmse_gd)\n",
    "    plt.plot(alp,rmse_irls)\n",
    "    plt.xlabel(\"Learning Paramter\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    # IRLS in Orange\n",
    "    # Gradient Descent in Blue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
